{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "golfposerscrape.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hedgehog-genki/ajax_app/blob/master/golfposerscrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwd769RcSQzj"
      },
      "source": [
        "## グーグルドライブのマウント\n",
        "実行するとURLが表示されるので、アクセスしてワンタイムキーを取得して、入力してください。\n",
        "\n",
        "### 実行後、対象のURLリストをドライブに格納\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXbY4wF7SUad",
        "outputId": "8372f5c2-d794-48c7-9c48-ee87bafcfd43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLuLzN5XR-X7"
      },
      "source": [
        "スクリプトの実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F850UMMSRB4",
        "outputId": "54dee4f1-ed5b-4e71-a361-fa9a571eb66c"
      },
      "source": [
        "#必要なライブラリのインストール\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "!pip install requests-html\n",
        "\n",
        "#必要なライブラリのインポート\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import re\n",
        "from urllib.request import urlopen\n",
        "import urllib.request, urllib.error\n",
        "from requests_html import HTMLSession\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import csv\n",
        "import pprint\n",
        "\n",
        "#スクレイピング対象のリストをインポートする\n",
        "with open(\"/content/在庫確認納品用 - 出力用 (6).csv\") as f: #ファイルパスを取得して貼り付け\n",
        "  reader = csv.reader(f)\n",
        "  l = [row for row in reader]\n",
        "\n",
        "l_str = [str(n) for n in l]\n",
        "#l_strがスクレイピング対象のURLが格納されるリストになります。\n",
        "\n",
        "#スクレイピングのスクリプト\n",
        "#実行するためのスクリプト(変更することはありません)\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "driver.implicitly_wait(10)\n",
        "\n",
        "#スクレイピングで取得した情報を格納するリストの宣言\n",
        "price_list = []\n",
        "select_list = []\n",
        "title_list = []\n",
        "\n",
        "#l_strリストに格納されたURLに順番にアクセスしてスクレイピングを実行\n",
        "for n in l_str:\n",
        "  #URLにアクセスできるように文字列を置き換える\n",
        "  url4=n\n",
        "  url3=url4.replace(\"'\",\"\")\n",
        "  url2=url3.replace(\"[\",\"\")\n",
        "  url=url2.replace(\"]\",\"\")\n",
        "  #URLにアクセス\n",
        "  driver.get(url)\n",
        "  html = driver.page_source.encode('utf-8')\n",
        "  #BeautifulSoupを使用してHTML要素を取得する\n",
        "  soup = BeautifulSoup(html,\"html.parser\")\n",
        "  #価格情報を取得して文字列を整理してからprice_listに格納する\n",
        "  testprice = soup.find(\"div\",attrs={\"class\":\"product-info-price\"})\n",
        "  preprice = testprice.text\n",
        "  rpreprice = preprice.replace(\"\\n\",\"\")\n",
        "  price = rpreprice.replace(\"As low as\",\"\")\n",
        "  price_list.append(price)\n",
        "  #タイトルの取得\n",
        "  title = soup.find(\"h1\",attrs={\"class\":\"page-title\"})\n",
        "  titletext = title.text\n",
        "  title_list.append(titletext)\n",
        "  #在庫情報の取得\n",
        "  testselect = soup.find_all(\"select\",attrs={\"super-attribute-select\"})\n",
        "  #取得した在庫情報をselect_listに格納する\n",
        "  for s in testselect:\n",
        "    pre = s.text\n",
        "    pretext = pre.replace(\"\\nSelect Size\",\"\")\n",
        "    select_list.append(pretext)\n",
        "\n",
        "#取得した価格情報と在庫情報をCSVで出力する\n",
        "df_price = pd.DataFrame(price_list)\n",
        "df_select = pd.DataFrame(select_list)\n",
        "df_title = pd.DataFrame(title_list)\n",
        "df = pd.concat([df_title,df_price,df_select],axis=1)\n",
        "df.columns = [\"title\",\"price\",\"stock\"]\n",
        "df.to_csv(\"stockinfo.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (91.0.4472.101-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 98 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.25.11)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests-html) (1.22.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests-html) (1.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests-html) (2.23.0)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests-html) (0.2.5)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests-html) (1.4.3)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html) (0.0.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests-html) (0.1.11)\n",
            "Requirement already satisfied: importlib-metadata<3.0.0,>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (2.1.1)\n",
            "Requirement already satisfied: websockets<9.0,>=8.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.1)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.62.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.25.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0.0,>=2.1.1->pyppeteer>=0.0.14->requests-html) (3.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html) (4.6.3)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html) (1.1.0)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html) (4.2.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (2.10)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from w3lib->requests-html) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh4F8ZqEanzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd55ed3d-de99-4a3c-81ef-3caedbcf07d8"
      },
      "source": [
        "price_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$40.00',\n",
              " '$130.00',\n",
              " '$70.00',\n",
              " '$200.00',\n",
              " '$35.00',\n",
              " '$35.00',\n",
              " '$35.00',\n",
              " ' Was$94.00$66.00',\n",
              " '$66.00',\n",
              " '$110.00',\n",
              " ' Was$125.00$88.00']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTOj3C2uctbU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}